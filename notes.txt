repeat_action_probability:
Probability of the previously executed action being used as the next action,
instead of an action being chosen and passed to the environment.
These so-called sticky actions are a way of introducing stochasticity into otherwise deterministic environments, largely for benchmarking.


DQN: Deep Q Network -> CNN treinada com variante de Q-learning
input = raw pixels
output = função VALUE estimadora de rewards futuros

hyper parametros:
- Learning Rate (step size)
- Discount factor (determina importancia de rewards futuros)
- condições iniciais (Q0)

our changes:
- changing color scoring

NÃO CONSEGUIMOS:
- diferenciar as pontuações por cores de cada bloco. tentámos soluções de computer vision mas não conseguimos selecionar os blocos. 



OBSERVAÇÕES:
Após executarmos a função see_observation() do módulo 'visualizing_observations.py', depreendemos o seguinte:
- os blocos azuis estão entre os píxeis (87,8) e (92,151) e o seu código RGB é (66,72,200);
- os blocos verdes estão entre os píxeis (81,8) e (86,151) e o seu código RGB é (72,160,72);
- os blocos amarelos estão entre os píxeis (75,8) e (80,151) e o seu código RGB é (162,162,42);
- a camada inferior de blocos cor de laranja estão entre os píxeis (69,8) e (74,151) e o seu código RGB é (180,122,48);
- a camada superior de blocos cor de laranja estão entre os píxeis (63,8) e (68,151) e o seu código RGB é (198,108,58);
- os blocos vermelhos estão entre os píxeis (57,8) e (62,151) e o seu código RGB é (200,72,72).
